# Backend-LevelTest

---

# 🖥️ 서버 설명

- 개발 역량 진단을 위한 AI 기반의 자동 채점 및 분석 백엔드 서버입니다.
- 수강생이 학습을 원하는 관심 분야(카테고리)를 선택하면, 서버에서 해당 분야 10개의 서술형 문제를 수강생에게 제공합니다.
- 답변이 제출되면, 비동기로 채점이 시작됩니다.
- 채점이 완료되면, 채점된 내용 기반으로 종합 레포트를 생성합니다.
- 종합 레포트 생성이 되면, Kafka 이벤트 처리를 통해 수강생에게 알림이 제공됩니다.
- 이후 수강생은 본인이 푼 문제에 대해서 종합 레포트를 확인할 수 있습니다.
- 패키지 구조
```
leveltest
    ├─main
    │  ├─java/com/lgcms/leveltest
    │  │  ├─common
    │  │  │  ├─dto
    │  │  │  └─kafka
    │  │  ├─config
    │  │  ├─controller
    │  │  ├─domain
    │  │  ├─dto
    │  │  ├─event
    │  │  ├─repository
    │  │  └─service
    │  └─resources
    └─test/java/com/lgcms/leveltest
```
---

# 👨🏻‍💻 담당자

| 이름  | 역할                |
|-----|-------------------|
| 조민준 | Level Test 백엔드 개발 |
| 이재원 | CI/CD, 모니터링       |

---

# 🛠️ 기술 스택

### Languages

![java](https://img.shields.io/badge/Java-007396?style=for-the-badge&logo=openjdk&logoColor=white)

### Framework

![Spring Boot](https://img.shields.io/badge/Spring_Boot-6DB33F?style=flat-square&logo=spring-boot&logoColor=white)

### Middleware

![Apache Kafka](https://img.shields.io/badge/Apache_Kafka-231F20?style=flat-square&logo=apache-kafka&logoColor=white)
![OpenTelemetry](https://img.shields.io/badge/OpenTelemetry-FFB01F?style=flat-square&logo=opentelemetry&logoColor=black)
### Database

![Redis](https://img.shields.io/badge/Redis-DC382D?style=flat-square&logo=redis&logoColor=white)
![PostgreSQL](https://img.shields.io/badge/PostgreSQL-4169E1?style=flat-square&logo=postgresql&logoColor=white)
---

# 📌 기능

### ✔️ 관심 분야 카테고리 기반 레벨 테스트 문제 제공
- 수강생 → API 서버 : 관심 분야 카테고리 ID를 포함하여 문제 생성 요청
- API 서버:
    - 요청된 카테고리에 해당하는 문제들을 DB에서 조회합니다.
    - '하(3), 중(4), 상(3)'의 난이도 비율에 맞춰 10개의 문제를 랜덤으로 조합합니다.
    - API 서버 → 수강생: 조합된 10개의 문제 목록을 응답으로 반환합니다.

#### 사용자가 원하는 관심 분야를 선택하면, 해당 분야의 역량을 평가할 수 있는 10개의 서술형 문제가 난이도별로 자동 구성되어 제공됩니다.

### ✔️ 비동기 LLM 채점 및 리포트 생성
- 사용자 → API 서버: 작성한 10개의 답변을 일괄 제출
- API 서버:
  - DB에 답변을 채점 대기 상태로 저장합니다.
  - 비동기 채점 서비스를 호출합니다.
  - 사용자에게 제출 완료 응답을 즉시 반환합니다.

- 비동기 채점 서비스 (백그라운드 실행):
    - [1단계] 문항별 채점: 제출된 10개의 답변을 하나씩 LLM에게 전송하여 채점을 진행합니다.
    채점 결과를 DB에 업데이트합니다.
    
    - [2단계] 핵심 개념 분석: 채점이 완료된 답변 전체를 기반으로 LLM이 핵심 개념 이해도를 분석합니다.
    
    - [3단계] 종합 피드백 생성: AI가 모든 분석 결과를 바탕으로 종합 피드백 및 학습 추천 내용을 생성합니다.
    
    - [4단계] 레포트 생성 및 저장 : 모든 분석 결과를 취합하여 DB에 최종 리포트를 생성 및 저장합니다.

- Kafka Producer: 리포트 생성 완료 이벤트를 Kafka 토픽으로 발행합니다.
- 알림 서버 (Kafka Consumer): 이벤트를 수신하여 사용자에게 알림을 전송합니다.


#### 답변 제출 시, 무거운 채점 작업은 백그라운드에서 비동기적으로 처리됩니다. 3단계에 걸친 AI 분석을 통해 상세한 채점, 심층적인 개념 이해도 분석, 맞춤형 종합 피드백이 포함된 리포트가 생성되며, 완료 시 Kafka를 통해 사용자에게 알림이 전송됩니다.

---

# 📜 주요 기능 
### 관심 분야 선택 및 맞춤형 문제 제공
- 사용자는 Spring, React, Database 등 원하는 기술 스택을 선택하여 개발 기술 관련 역량 진단 테스트를 받을 수 있습니다.

### LLM 기반 서술형 문제 자동 채점
- LLM이 사용자 답변을 채점하고 상세한 개념별 이해도 기반 피드백을 제공합니다.

### 심층 분석 종합 레포트 생성
- 개별 문항 채점 결과를 넘어, 테스트 전반에 걸친 핵심 개념 이해도를 별도로 분석하고 종합적인 강점, 약점, 추천 학습 방향을 제시하는 레포트를 제공합니다.

### 이벤트 기반의 실시간 알림
- 레포트 생성이 완료되면 Kafka 이벤트를 통해 사용자에게 즉시 알림을 보내 결과를 바로 확인할 수 있도록 합니다.
---

# ⚡ 트러블슈팅

### 수강생의 레포트 히스토리 최신 카테고리로 모든 기록의 카테고리 저장 이슈
- 문제 현상
  - 레포트 히스토리 조회 시, 과거에 응시했던 모든 레포트의 카테고리가 가장 최근에 응시한 시험의 카테고리로 통일되어 표시되는 오류가 발생했습니다. (예: 과거 'Java' 레포트가 'Docker'로 표시됨)
- 원인 분석
  - 데이터 설계 오류: LevelTestReport 엔티티에 어떤 카테고리의 시험이었는지 기록하는 category 필드가 누락되어 있었습니다. 
  - 잘못된 동적 조회: 카테고리 정보가 없었기 때문에, 히스토리를 조회할 때마다 "회원의 가장 최근 답변 10개"를 기준으로 카테고리를 실시간으로 추측했습니다. 이 때문에 모든 과거 리포트가 항상 최신 시험의 카테고리를 따라가는 문제가 발생했습니다.
- 해결 과정
  - 엔티티 수정: LevelTestReport 엔티티에 category 필드를 추가하여, 리포트 생성 시점의 카테고리 정보가 영구적으로 저장되도록 데이터 모델을 수정했습니다.
  - 생성 로직 수정: createReport 메서드가 실행될 때, 해당 시험의 카테고리 정보를 조회하여 새 category 필드에 저장하도록 로직을 변경했습니다.
  - 조회 로직 단순화: 불필요하고 잘못된 동적 조회 로직을 제거하고, DB에 저장된 각 리포트의 category 값을 직접 읽어오도록 수정하여 문제를 해결하고 성능을 개선했습니다.

###  LLM 채점 '개념 이해도 점수' 범위 초과 이슈
- 문제 현상
  - LLM이 반환하는 '개념별 이해도' 점수가 약속된 1~5점 범위를 초과하는 값(예: 7점, 8점)으로 생성되었습니다. 이로 인해 리포트 생성 중 시스템 오류가 발생했습니다.

- 원인 분석
  - 초기에는 AI가 규칙을 따르지 않는 문제로 추측했으나, 진짜 원인은 프롬프트 설계의 모호성에 있었습니다. 
  - 개별 문제 채점 프롬프트(GradingPrompt.java)의 JSON 응답 형식 내에, 이름은 같지만(score) 의미와 범위가 다른 두 필드가 공존했습니다.
  - LLM이 두 score 필드의 맥락을 혼동하여, '개념 이해도 점수'에 '문제 전체 점수'의 넓은 범위를 잘못 적용한 것이 핵심 원인이었습니다.

- 해결 과정 
  - 프롬프트 명확화 (원인 제거): AI의 혼란을 막기 위해 프롬프트 내 studentScore 필드명을 questionScore로 변경하여, '문제 점수'와 '개념 점수'를 명확히 분리했습니다. 
  - 코드 레벨 방어 로직 추가 (안정성 확보): AI 응답을 100% 신뢰할 수 없다는 원칙 하에, AI로부터 받은 점수를 DB에 저장하기 전 애플리케이션 레벨에서 값을 강제로 보정하는 로직을 추가했습니다.
---

# 💡 느낀점

1. LLM 프롬프트에 대해서 많이 배웠습니다.
2. 전반적으로 MSA 환경에서 Spring을 처음 써보면서 dto부터 config, Service로직 등등 많은 것을 경험할 수 있었습니다.
3. Kafka 이벤트 처리하는 부분을 처음 접해봤는데 아직 많이 어렵지만 이것 또한 배울 수 있어서 좋았습니다.